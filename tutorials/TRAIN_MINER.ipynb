{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CoGames Puffer Training - Miner Tutorial\n",
    "\n",
    "This notebook replicates the training setup from:\n",
    "```\n",
    "cogames train -m miner_tutorial -p tutorial\n",
    "```\n",
    "\n",
    "It walks through:\n",
    "1. Building the environment from the miner_tutorial mission\n",
    "2. Token-to-grid observation preprocessing\n",
    "3. Defining a CNN + LSTM policy network from scratch\n",
    "4. Vectorizing with PufferLib\n",
    "5. Running the PuffeRL training loop\n",
    "6. Uploading to the CoGames leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install mettagrid cogames pufferlib-core --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import torch\nimport torch.nn as nn\nfrom einops import rearrange\nimport pufferlib.vector as pvector\nfrom pufferlib import pufferl\nfrom pufferlib.pufferlib import set_buffers\n\nfrom mettagrid import MettaGridConfig\nfrom mettagrid.envs.mettagrid_puffer_env import MettaGridPufferEnv\nfrom mettagrid.envs.early_reset_handler import EarlyResetHandler\nfrom mettagrid.envs.stats_tracker import StatsTracker\nfrom mettagrid.mapgen.mapgen import MapGen\nfrom mettagrid.policy.policy_env_interface import PolicyEnvInterface\nfrom mettagrid.simulator import Simulator\nfrom mettagrid.simulator.replay_log_writer import InMemoryReplayWriter\nfrom mettagrid.util.stats_writer import NoopStatsWriter\n\nfrom cogames.cogs_vs_clips.clip_difficulty import EASY\nfrom cogames.cogs_vs_clips.tutorials.miner_tutorial import MinerRewardsVariant\nfrom cogames.cogs_vs_clips.mission import CvCMission\nfrom cogames.cogs_vs_clips.sites import make_cogsguard_machina1_site\nfrom cogames.cogs_vs_clips.team import CogTeam\nfrom cogames.cogs_vs_clips.variants import NoVibesVariant"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Build the mission and environment config\n",
    "\n",
    "We construct a CvCMission from scratch:\n",
    "- **Site**: Machina1 layout with 4 spawn points (hub junction starts aligned to cogs)\n",
    "- **EASY difficulty**: Disables clips events\n",
    "- **1000 max steps** per episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_AGENTS = 4\n",
    "MAX_STEPS = 1000\n",
    "\n",
    "# Build the mission\n",
    "# EASY variant disables clips events\n",
    "# NoVibesVariant disables vibes so miners focus purely on mining\n",
    "# MinerRewardsVariant adds miner-focused reward shaping (gear, resource extraction, deposits)\n",
    "mission = CvCMission(\n",
    "    name=\"miner_tutorial\",\n",
    "    description=\"Learn miner role - resource extraction and deposits.\",\n",
    "    site=make_cogsguard_machina1_site(NUM_AGENTS),\n",
    "    num_cogs=NUM_AGENTS,\n",
    "    max_steps=MAX_STEPS,\n",
    "    teams={\"cogs\": CogTeam(name=\"cogs\", num_agents=NUM_AGENTS)},\n",
    "    variants=[EASY, NoVibesVariant(), MinerRewardsVariant()],\n",
    ")\n",
    "\n",
    "env_cfg: MettaGridConfig = mission.make_env()\n",
    "\n",
    "print(f\"Map builder: {type(env_cfg.game.map_builder).__name__}\")\n",
    "print(f\"Max steps: {env_cfg.game.max_steps}\")\n",
    "print(f\"Num agents: {env_cfg.game.num_agents}\")\n",
    "print(f\"Actions: {[a for a in env_cfg.game.actions.model_fields if getattr(env_cfg.game.actions, a).enabled]}\")\n",
    "print(f\"Events: {list(env_cfg.game.events.keys())}\")\n",
    "print(f\"Teams: {[t for t in env_cfg.game.tags if t.startswith('team:')]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create a single environment\n",
    "\n",
    "MettaGridPufferEnv wraps the C++ simulator with PufferLib's PufferEnv interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "def make_env(buf=None, seed=None):\n",
    "    \"\"\"Environment factory for PufferLib vectorization.\"\"\"\n",
    "    cfg = env_cfg.model_copy(deep=True)\n",
    "\n",
    "    map_builder = cfg.game.map_builder\n",
    "    if isinstance(map_builder, MapGen.Config) and seed is not None:\n",
    "        map_builder.seed = SEED + seed\n",
    "\n",
    "    simulator = Simulator()\n",
    "    simulator.add_event_handler(StatsTracker(NoopStatsWriter()))\n",
    "    simulator.add_event_handler(EarlyResetHandler())\n",
    "    env = MettaGridPufferEnv(simulator, cfg, buf=buf, seed=seed or 0)\n",
    "    set_buffers(env, buf)\n",
    "    return env\n",
    "\n",
    "\n",
    "# Create a driver env to inspect observation/action spaces\n",
    "driver_env = make_env(seed=0)\n",
    "policy_env_info = PolicyEnvInterface.from_mg_cfg(driver_env.env_cfg)\n",
    "\n",
    "print(f\"Observation space: {driver_env.single_observation_space}\")\n",
    "print(f\"Action space: {driver_env.single_action_space}\")\n",
    "print(f\"Num agents: {driver_env.num_agents}\")\n",
    "print(f\"Action names: {policy_env_info.action_names}\")\n",
    "print(f\"Obs features: {len(policy_env_info.obs_features)} features\")\n",
    "print(f\"Obs grid: {policy_env_info.obs_height}x{policy_env_info.obs_width}\")\n",
    "driver_env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Observation preprocessing\n",
    "\n",
    "MettaGrid observations are sparse tokens `[B, T, 3]` where each token is `[packed_xy, feature_id, value]`. The packed byte encodes grid coordinates as nibbles: `y = byte >> 4, x = byte & 0x0F`.\n",
    "\n",
    "We scatter these into a dense spatial grid `[B, C, H, W]` so a CNN can process them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens_to_grid(\n",
    "    observations: torch.Tensor,\n",
    "    obs_height: int,\n",
    "    obs_width: int,\n",
    "    num_features: int,\n",
    "    feature_scale: torch.Tensor,\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"Convert sparse token observations [B, T, 3] into a dense grid [B, C, H, W].\"\"\"\n",
    "    batch_size = observations.shape[0]\n",
    "    device = observations.device\n",
    "\n",
    "    coords_byte = observations[..., 0].to(torch.long)\n",
    "    x_coords = coords_byte & 0x0F\n",
    "    y_coords = (coords_byte >> 4) & 0x0F\n",
    "    feature_ids = observations[..., 1].to(torch.long)\n",
    "    values = observations[..., 2].to(torch.float32)\n",
    "\n",
    "    valid_mask = (observations[..., 0] != 0xFF).float()\n",
    "    x_coords = torch.clamp(x_coords, 0, obs_width - 1)\n",
    "    y_coords = torch.clamp(y_coords, 0, obs_height - 1)\n",
    "    feature_ids_clamped = torch.clamp(feature_ids, 0, num_features - 1)\n",
    "\n",
    "    scale = feature_scale[torch.clamp(feature_ids, 0, feature_scale.shape[0] - 1)]\n",
    "    values = (values / (scale + 1e-6)) * valid_mask\n",
    "\n",
    "    grid = torch.zeros(batch_size, num_features, obs_height, obs_width, device=device)\n",
    "    batch_idx = torch.arange(batch_size, device=device).unsqueeze(1).expand_as(x_coords)\n",
    "    linear_idx = (\n",
    "        batch_idx * (num_features * obs_height * obs_width)\n",
    "        + feature_ids_clamped * (obs_height * obs_width)\n",
    "        + y_coords * obs_width\n",
    "        + x_coords\n",
    "    )\n",
    "    grid.view(-1).scatter_add_(0, linear_idx.view(-1), values.view(-1))\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Build the neural network\n",
    "\n",
    "CNN + LSTM actor-critic:\n",
    "- **CNN encoder**: Two 3x3 conv layers (64 → 128) with stride 2, projected to 256-dim\n",
    "- **Self encoder**: Linear on the center cell (agent's own state) → 256-dim\n",
    "- **LSTM**: 512 hidden units, 1 layer\n",
    "- **Action head**: Linear → num_actions logits\n",
    "- **Value head**: Linear → scalar value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    DEVICE = torch.device(\"mps\")\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Device: {DEVICE}\")\n",
    "\n",
    "\n",
    "class MinerPolicyNet(nn.Module):\n",
    "    \"\"\"CNN + LSTM actor-critic.\"\"\"\n",
    "\n",
    "    _feature_scale: torch.Tensor\n",
    "\n",
    "    def __init__(self, env_info: PolicyEnvInterface):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_size = 512\n",
    "        self._obs_height = env_info.obs_height\n",
    "        self._obs_width = env_info.obs_width\n",
    "        self._num_features = max((int(f.id) for f in env_info.obs_features), default=0) + 1\n",
    "\n",
    "        # Feature normalization buffer\n",
    "        feature_norms = {f.id: f.normalization for f in env_info.obs_features}\n",
    "        max_id = max((int(fid) for fid in feature_norms.keys()), default=-1)\n",
    "        feature_scale = torch.ones(max(256, max_id + 1), dtype=torch.float32)\n",
    "        for fid, norm in feature_norms.items():\n",
    "            feature_scale[fid] = max(float(norm), 1.0)\n",
    "        self.register_buffer(\"_feature_scale\", feature_scale)\n",
    "\n",
    "        # CNN encoder\n",
    "        self._cnn = nn.Sequential(\n",
    "            nn.Conv2d(self._num_features, 64, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "        with torch.no_grad():\n",
    "            dummy = torch.zeros(1, self._num_features, self._obs_height, self._obs_width)\n",
    "            cnn_out_size = self._cnn(dummy).shape[1]\n",
    "\n",
    "        self._cnn_fc = nn.Linear(cnn_out_size, 256)\n",
    "        self._self_encoder = nn.Linear(self._num_features, 256)\n",
    "        self._rnn = nn.LSTM(self.hidden_size, self.hidden_size, num_layers=1, batch_first=True)\n",
    "\n",
    "        num_actions = len(env_info.action_names)\n",
    "        self._action_head = nn.Linear(self.hidden_size, num_actions)\n",
    "        self._value_head = nn.Linear(self.hidden_size, 1)\n",
    "\n",
    "    def forward(self, observations: torch.Tensor, state: dict[str, torch.Tensor] | None = None) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        orig_shape = observations.shape\n",
    "        if observations.dim() == 4:\n",
    "            segments, bptt_horizon = orig_shape[0], orig_shape[1]\n",
    "            observations = observations.reshape(segments * bptt_horizon, *orig_shape[2:])\n",
    "        else:\n",
    "            segments, bptt_horizon = orig_shape[0], 1\n",
    "\n",
    "        grid = tokens_to_grid(observations, self._obs_height, self._obs_width, self._num_features, self._feature_scale)\n",
    "        cnn_out = torch.relu(self._cnn_fc(self._cnn(grid)))\n",
    "        center = grid[:, :, self._obs_height // 2, self._obs_width // 2]\n",
    "        self_out = torch.relu(self._self_encoder(center))\n",
    "\n",
    "        hidden = torch.cat([cnn_out, self_out], dim=-1)\n",
    "        hidden = rearrange(hidden, \"(b t) h -> b t h\", t=bptt_horizon, b=segments)\n",
    "\n",
    "        rnn_state = None\n",
    "        if state is not None:\n",
    "            h, c = state.get(\"lstm_h\"), state.get(\"lstm_c\")\n",
    "            if h is not None and c is not None:\n",
    "                h = h.transpose(0, 1) if h.dim() == 3 else h.unsqueeze(0)\n",
    "                c = c.transpose(0, 1) if c.dim() == 3 else c.unsqueeze(0)\n",
    "                rnn_state = (h, c)\n",
    "\n",
    "        hidden, (h_out, c_out) = self._rnn(hidden, rnn_state)\n",
    "\n",
    "        if state is not None and \"lstm_h\" in state:\n",
    "            state[\"lstm_h\"] = h_out.transpose(0, 1)\n",
    "            state[\"lstm_c\"] = c_out.transpose(0, 1)\n",
    "\n",
    "        hidden = rearrange(hidden, \"b t h -> (b t) h\")\n",
    "        return self._action_head(hidden), self._value_head(hidden)\n",
    "\n",
    "    forward_eval = forward\n",
    "\n",
    "\n",
    "net = MinerPolicyNet(policy_env_info).to(DEVICE)\n",
    "\n",
    "print(f\"\\nArchitecture:\\n{net}\")\n",
    "total_params = sum(p.numel() for p in net.parameters())\n",
    "print(f\"\\nTotal parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Vectorize environments with PufferLib\n",
    "\n",
    "PufferLib's vectorized environment runs multiple env copies in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_ENVS = 4  # Keep small for notebook; cogames defaults to 256\n",
    "\n",
    "# Serial backend — spawn multiprocessing can't find notebook-defined functions\n",
    "vecenv = pvector.make(\n",
    "    make_env,\n",
    "    num_envs=NUM_ENVS,\n",
    "    num_workers=1,\n",
    "    batch_size=NUM_ENVS,\n",
    "    backend=pvector.Serial,\n",
    ")\n",
    "\n",
    "total_agents = vecenv.num_agents\n",
    "print(f\"Vectorized envs: {NUM_ENVS}\")\n",
    "print(f\"Total agents across all envs: {total_agents}\")\n",
    "print(f\"Agents per env: {total_agents // NUM_ENVS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Configure and run PuffeRL training\n",
    "\n",
    "These hyperparameters match what `cogames train` uses in `cogames/train.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "TOTAL_TIMESTEPS = 10_000_000\nBPTT_HORIZON = 64  # Truncated BPTT window for LSTM\nBATCH_SIZE = max(4096, total_agents * BPTT_HORIZON)\nMINIBATCH_SIZE = min(4096, BATCH_SIZE)\n\ntrain_config = dict(\n    env=\"cogames.cogs_vs_clips\",\n    device=DEVICE.type,\n    total_timesteps=max(TOTAL_TIMESTEPS, BATCH_SIZE),\n    batch_size=BATCH_SIZE,\n    minibatch_size=MINIBATCH_SIZE,\n    bptt_horizon=BPTT_HORIZON,\n    seed=SEED,\n    use_rnn=True,\n    torch_deterministic=True,\n    cpu_offload=False,\n    compile=False,\n\n    # Optimizer\n    optimizer=\"adam\",\n    learning_rate=0.00092,\n    anneal_lr=True,\n    min_lr_ratio=0.0,\n    adam_beta1=0.95,\n    adam_beta2=0.999,\n    adam_eps=1e-8,\n\n    # PPO\n    precision=\"float32\",\n    gamma=0.995,\n    gae_lambda=0.90,\n    update_epochs=1,\n    clip_coef=0.2,\n    vf_coef=2.0,\n    vf_clip_coef=0.2,\n    max_grad_norm=1.5,\n    ent_coef=0.01,\n\n    # Sampling\n    vtrace_rho_clip=1.0,\n    vtrace_c_clip=1.0,\n    prio_alpha=0.8,\n    prio_beta0=0.2,\n\n    # Checkpointing\n    data_dir=\"./train_dir\",\n    checkpoint_interval=50,\n    max_minibatch_size=32768,\n)\n\nprint(\"Training config:\")\nfor k, v in train_config.items():\n    print(f\"  {k}: {v}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pufferl.PuffeRL(train_config, vecenv, net)\n",
    "\n",
    "print(f\"Model size: {trainer.model_size:,} params\")\n",
    "print(f\"Batch size: {trainer.config['batch_size']}\")\n",
    "print(f\"Minibatch size: {trainer.minibatch_size}\")\n",
    "print(f\"BPTT horizon: {trainer.config['bptt_horizon']}\")\n",
    "print(f\"Total epochs: {trainer.total_epochs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "# Training loop\n",
    "while trainer.global_step < train_config[\"total_timesteps\"]:\n",
    "    trainer.evaluate()\n",
    "    trainer.train()\n",
    "\n",
    "    clear_output(wait=True)\n",
    "    trainer.print_dashboard()\n",
    "\n",
    "    # Check for NaN divergence\n",
    "    has_nan = any(\n",
    "        (p.grad is not None and not p.grad.isfinite().all()) or not p.isfinite().all()\n",
    "        for p in net.parameters()\n",
    "    )\n",
    "    if has_nan:\n",
    "        print(f\"Training diverged at step {trainer.global_step}!\")\n",
    "        break\n",
    "\n",
    "trainer.close()\n",
    "print(f\"Training complete. Steps: {trainer.global_step}, Epochs: {trainer.epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained weights\n",
    "save_path = \"./train_dir/tutorial_miner.pt\"\n",
    "torch.save(net.state_dict(), save_path)\n",
    "print(f\"Saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 7. Watch the trained policy in MettaScope\n\nRun the trained network for a full episode and view the replay in the interactive MettaScope viewer."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import base64\nimport json\nimport zlib\nfrom IPython.display import HTML, Javascript, display\n\n# Run an episode and capture replay\nreplay_writer = InMemoryReplayWriter()\nrender_env = make_env(seed=99)\nrender_env._simulator.add_event_handler(replay_writer)\nobs, _ = render_env.reset()\n\nnum_agents = render_env.num_agents\nstate = {\n    \"lstm_h\": torch.zeros(num_agents, 1, net.hidden_size, device=DEVICE),\n    \"lstm_c\": torch.zeros(num_agents, 1, net.hidden_size, device=DEVICE),\n}\n\nnet.eval()\nnum_steps = 0\nfor _step in range(MAX_STEPS):\n    obs_tensor = torch.from_numpy(obs).to(DEVICE)\n    with torch.no_grad():\n        logits, _ = net(obs_tensor, state)\n    actions = torch.distributions.Categorical(logits=logits).sample().cpu().numpy()\n    obs, rewards, terms, truncs, infos = render_env.step(actions)\n    num_steps += 1\n    if terms.all() or truncs.all():\n        break\n\nprint(f\"Episode finished after {num_steps} steps\")\n\n# Get replay data before closing (needs live simulation for episode stats)\nreplays = replay_writer.get_completed_replays()\nreplay_data = json.dumps(replays[0].get_replay_data())\nrender_env.close()\n\n# Compress and encode\ncompressed = zlib.compress(replay_data.encode(\"utf-8\"))\nb64 = base64.b64encode(compressed).decode(\"utf-8\")\n\n# Display MettaScope iframe\niframe_src = \"https://metta-ai.github.io/metta/mettascope/mettascope.html\"\niframe_id = \"mettascope_iframe\"\n\ndisplay(HTML(f'''\n<div>\n    <iframe id=\"{iframe_id}\" src=\"{iframe_src}\" width=\"100%\" height=\"800\"\n            style=\"border: 1px solid #ccc; border-radius: 4px;\"></iframe>\n</div>\n'''))\n\nb64_escaped = b64.replace('\\\\', '\\\\\\\\').replace(\"'\", \"\\\\'\").replace('\\n', '\\\\n')\ndisplay(Javascript(f'''\n(function() {{\n    const iframe = document.getElementById('{iframe_id}');\n    const base64Data = '{b64_escaped}';\n    function sendReplayData() {{\n        iframe.contentWindow.postMessage({{\n            type: 'replayData',\n            base64: base64Data,\n            fileName: 'tutorial_replay.json.z'\n        }}, '*');\n    }}\n    window.addEventListener('message', function(event) {{\n        if (event.data.type === 'mettascopeReady') {{\n            sendReplayData();\n        }}\n    }});\n}})();\n'''))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Upload to the leaderboard\n",
    "\n",
    "Submit the trained weights to the CoGames tournament. This uses the `tutorial` policy class\n",
    "(same architecture as `MinerPolicyNet`) with our saved weights.\n",
    "\n",
    "Prerequisites: run `cogames login` in a terminal first to authenticate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "POLICY_NAME = \"my-miner-tutorial\"  # Change this to your desired policy name\n",
    "\n",
    "!cogames upload -p \"class=tutorial,data={save_path}\" -n {POLICY_NAME} --skip-validation"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}