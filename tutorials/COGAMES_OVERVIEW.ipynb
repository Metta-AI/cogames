{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "welcome",
   "metadata": {},
   "source": "# CoGames: Getting Started\n\nWelcome to CoGames! This notebook will get you from zero to training your own agent.\n\nCoGames is built on **MettaGrid**, a grid-world simulation engine. The flagship game mode\nis **Cogs vs Clips** — a cooperative territory-control game where teams of specialized agents\n(Cogs) capture and defend junctions against automated expansion by Clips.\n\nThis notebook covers:\n1. Installing cogames and playing the interactive tutorials\n2. How to create an environment and what parameters you can configure\n3. What the observation and action spaces look like"
  },
  {
   "cell_type": "markdown",
   "id": "install",
   "metadata": {},
   "source": "## 1. Install and Play\n\nInstall the cogames package:\n\n```bash\npip install cogames\n```\n\nThen run the two interactive tutorials to learn the game mechanics before writing any code.\n\n### `cogames tutorial play`\n\nThis launches a guided walkthrough in MettaScope where you control a single agent.\nIt teaches you the basics step by step:\n- Camera controls (scroll/pinch to zoom, drag to pan)\n- Movement and energy (WASD/arrows, battery drains, recharge near Hub)\n- Gear stations (pick a role: Aligner, Scrambler, Miner, Scout)\n- Resources and hearts (extract resources at Extractors, craft Hearts at the Assembler)\n- Junction control (Aligners capture neutral junctions, Scramblers neutralize enemy ones)\n\n```bash\ncogames tutorial play\n```\n\n### `cogames tutorial cogsguard`\n\nThis is a deeper tutorial focused on the full Cogs vs Clips game loop on a smaller 35x35 arena.\nIt walks through multi-phase strategy:\n- Gear up and craft hearts\n- Expand from the Hub by capturing nearby junctions\n- Handle Clips pressure as they scramble your junctions\n- Use territory (friendly junctions restore HP and energy)\n- Coordinate roles and maintain the resource-to-heart pipeline\n\n```bash\ncogames tutorial cogsguard\n```\n\nOnce you understand the game, come back here to learn how to build environments\nand train agents programmatically."
  },
  {
   "cell_type": "markdown",
   "id": "env-intro",
   "metadata": {},
   "source": "## 2. Creating an Environment\n\nA Cogs vs Clips environment is built from a **mission**, which bundles a map, agent count,\ngame rules, and **variants** (modifiers that change difficulty or mechanics).\n\nThe mission produces a `MettaGridConfig`, which is passed to a `Simulator` and wrapped\nin a `MettaGridPufferEnv` (a Gymnasium-compatible env)."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "env-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install mettagrid cogames pufferlib-core --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "env-create",
   "metadata": {},
   "outputs": [],
   "source": "from cogames.cogs_vs_clips.clip_difficulty import EASY\nfrom cogames.cogs_vs_clips.cog import CogTeam\nfrom cogames.cogs_vs_clips.mission import CvCMission\nfrom cogames.cogs_vs_clips.sites import make_cogsguard_machina1_site\nfrom cogames.cogs_vs_clips.variants import NoVibesVariant\nfrom mettagrid.envs.mettagrid_puffer_env import MettaGridPufferEnv\nfrom mettagrid.policy.policy_env_interface import PolicyEnvInterface\nfrom mettagrid.simulator import Simulator\n\nNUM_AGENTS = 4\nMAX_STEPS = 1000\n\nmission = CvCMission(\n    name=\"my_mission\",\n    description=\"A simple Cogs vs Clips mission.\",\n    site=make_cogsguard_machina1_site(NUM_AGENTS),\n    num_cogs=NUM_AGENTS,\n    max_steps=MAX_STEPS,\n    teams={\"cogs\": CogTeam(name=\"cogs\", num_agents=NUM_AGENTS)},\n    variants=[EASY, NoVibesVariant()],\n)\n\nenv_cfg = mission.make_env()\npolicy_env_info = PolicyEnvInterface.from_mg_cfg(env_cfg)\n\n# Create and reset the environment\nsimulator = Simulator()\nenv = MettaGridPufferEnv(simulator, env_cfg, seed=42)\nobs, infos = env.reset()\n\nprint(f\"Agents: {env.num_agents}\")\nprint(f\"Max steps: {MAX_STEPS}\")\nprint(f\"Observation shape: {obs.shape}\")\nprint(f\"Action space: {policy_env_info.action_space}\")"
  },
  {
   "cell_type": "markdown",
   "id": "env-params",
   "metadata": {},
   "source": "### Key Mission Parameters\n\n| Parameter | What it controls |\n|-----------|------------------|\n| `site` | Map layout and size. `make_cogsguard_machina1_site(n)` gives an 88x88 arena. |\n| `num_cogs` | Number of agents on your team. |\n| `max_steps` | Episode length in ticks. |\n| `teams` | Team definitions (name, agent count, initial wealth). |\n| `variants` | List of modifiers that change game rules (see below). |\n\n### Variants\n\nVariants modify the environment after the base config is built. Stack them to create\ncustom training scenarios.\n\n**Role reward shaping** (dense rewards for learning a specific role):\n\n| Variant | Effect |\n|---------|--------|\n| `MinerRewardsVariant()` | Rewards gear pickup, resource extraction, and deposits |\n| `AlignerRewardsVariant()` | Rewards heart management and junction alignment |\n| `ScramblerRewardsVariant()` | Rewards gear pickup and junction scrambling |\n| `ScoutRewardsVariant()` | Rewards gear pickup and exploration/cell visitation |\n\n**Difficulty** (Clips pressure control):\n\n| Variant | Effect |\n|---------|--------|\n| `EASY` | Disables Clips events entirely |\n| `MEDIUM` | A few early Clips events, ending at step 300 |\n| `HARD` | Full Clips event system active |\n\n**Gameplay modifiers**:\n\n| Variant | Effect |\n|---------|--------|\n| `NoVibesVariant()` | Removes vibe actions (simplifies action space) |\n| `EnergizedVariant()` | Max energy + full regen, agents never run dry |\n| `BraveheartVariant()` | Hub starts with 255 hearts |\n| `ThickSkinnedVariant()` | No passive HP drain, only in enemy territory |\n| `DarkSideVariant()` | Zero solar energy regeneration |\n| `SuperChargedVariant()` | +2 to all energy regen |\n| `SharedRewards()` | All agents share the same reward signal |\n\n### Under the Hood: `MettaGridConfig`\n\n`mission.make_env()` returns a `MettaGridConfig` with a `GameConfig` inside. The game\nconfig controls everything the simulator needs:"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "env-config-inspect",
   "metadata": {},
   "outputs": [],
   "source": [
    "game = env_cfg.game\n",
    "\n",
    "print(\"=== Game Config ===\")\n",
    "print(f\"  num_agents:     {game.num_agents}\")\n",
    "print(f\"  max_steps:      {game.max_steps}\")\n",
    "print(f\"  resources:      {game.resource_names}\")\n",
    "print(f\"  obs window:     {game.obs.height}x{game.obs.width}\")\n",
    "print(f\"  obs tokens:     {game.obs.num_tokens} x {game.obs.token_dim}\")\n",
    "print(f\"  map builder:    {type(game.map_builder).__name__}\")\n",
    "print(f\"  objects:        {list(game.objects.keys())}\")\n",
    "\n",
    "actions = game.actions.actions()\n",
    "print(f\"  actions:        {[a.name for a in actions]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "obs-intro",
   "metadata": {},
   "source": "## 3. Observation Space\n\nEach agent receives a **sparse token observation** every step: a fixed-size buffer of\n3-element tokens `[coordinate, feature_id, value]`, dtype `uint8`.\n\n```\nobs shape per agent: (num_tokens, 3)   # default: (200, 3)\n```\n\n- **`coordinate`**: Packed `(row, col)` in a 13x13 egocentric window centered on the agent.\n  `0xFE` = global (non-spatial) token. `0xFF` = padding (end of valid tokens).\n- **`feature_id`**: Which feature this token describes (see list below).\n- **`value`**: The feature's value (0-255). Inventory amounts > 255 use multiple tokens\n  with `:p1`, `:p2` suffixes — reconstruct as `base + p1*256 + p2*65536`.\n\nThe observation is sparse: valid tokens come first, padding fills the rest."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "obs-features",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Observation shape per agent: {policy_env_info.observation_shape}\")\n",
    "print(f\"Egocentric window: {policy_env_info.obs_height}x{policy_env_info.obs_width}\")\n",
    "print(f\"\\nObservation features ({len(policy_env_info.obs_features)} total):\")\n",
    "print(f\"{'ID':>4}  {'Name':<30}  {'Normalization':>13}\")\n",
    "print(\"-\" * 52)\n",
    "for feat in policy_env_info.obs_features:\n",
    "    print(f\"{feat.id:>4}  {feat.name:<30}  {feat.normalization:>13.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "obs-features-explained",
   "metadata": {},
   "source": "Key features to know:\n- **`tag`** — object type at a cell (wall, junction, extractor, agent, etc.)\n- **`vibe`** — role/resource identity of the object\n- **`agent:group`** — team membership\n- **`aoe_mask`** — territory: 0=neutral, 1=friendly, 2=enemy\n- **`inv:*`** — agent inventory (energy, heart, resources, gear)\n- **`episode_completion_pct`**, **`last_action`**, **`last_reward`** — global agent state\n\nThe `tag` feature maps to object types via integer indices:"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "obs-tags",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tag mapping (tag value -> object type):\")\n",
    "for tag_id, tag_name in policy_env_info.tag_id_to_name.items():\n",
    "    print(f\"  {tag_id:>3}: {tag_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8bkb6yh3a8",
   "source": "### Converting to a Spatial Grid for CNNs\n\nThe raw sparse tokens aren't directly CNN-friendly. `GridObsWrapper` wraps the env\nso that `reset()` and `step()` return dense `(num_agents, C, H, W)` float32 grids\ninstead of sparse tokens — directly usable with CNNs.\n\nIt handles coordinate decoding (nibble-packed `(y, x)`), padding filtering (`0xFF`),\nglobal token placement (`0xFE` → grid center), and per-feature normalization.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "mrb0810n3g",
   "source": "from mettagrid.envs.grid_obs_wrapper import GridObsWrapper\n\ngrid_env = GridObsWrapper(env)\ngrid_obs, _ = grid_env.reset()\n\nprint(f\"Sparse tokens: {obs.shape}  ->  Dense grid: {grid_obs.shape}\")\nprint(f\"  {grid_obs.shape[0]} agents, {grid_obs.shape[1]} feature channels, \"\n      f\"{grid_obs.shape[2]}x{grid_obs.shape[3]} spatial\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "actions-intro",
   "metadata": {},
   "source": [
    "## 4. Action Space\n",
    "\n",
    "The action space is `Discrete(N)` — each step, every agent picks one integer action.\n",
    "\n",
    "Actions are split into **primary actions** (movement + noop) and **vibe actions**\n",
    "(changing the agent's vibe state). The `NoVibesVariant` used above removes vibe actions\n",
    "entirely, leaving only movement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "actions-list",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Primary action space: Discrete({len(policy_env_info.action_names)})\")\n",
    "print(f\"\\nPrimary actions:\")\n",
    "for i, name in enumerate(policy_env_info.action_names):\n",
    "    print(f\"  {i}: {name}\")\n",
    "\n",
    "if policy_env_info.vibe_action_names:\n",
    "    print(f\"\\nVibe actions ({len(policy_env_info.vibe_action_names)}):\")\n",
    "    for i, name in enumerate(policy_env_info.vibe_action_names):\n",
    "        print(f\"  {i}: {name}\")\n",
    "else:\n",
    "    print(\"\\nVibe actions: none (removed by NoVibesVariant)\")\n",
    "\n",
    "if policy_env_info.move_energy_cost is not None:\n",
    "    print(f\"\\nMove energy cost: {policy_env_info.move_energy_cost} per step\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "actions-explained",
   "metadata": {},
   "source": "### How Actions Work\n\n**Movement** (`move_north`, `move_south`, `move_west`, `move_east`): Moves the agent\none cell in the given direction. Costs energy. If the agent moves onto a building\n(extractor, gear station, junction, etc.), the building's handler fires — this is how\nagents interact with the world. Moving into a wall or off the map does nothing.\n\n**Noop**: Do nothing this step. Useful when waiting for cooldowns or conserving energy.\n\n**Vibe changes** (`change_vibe_*`): Switch the agent's vibe. Vibes determine how objects\nreact to the agent. In Cogs vs Clips, vibes represent resource types and roles — for example,\nan agent must be vibing `heart` to deposit hearts, or vibing `aligner` to capture a junction.\nWhen using `NoVibesVariant`, these are removed and vibes are handled automatically.\n\n### Interaction Model\n\nThere are no explicit \"use\" or \"pick up\" actions. All interactions happen through\n**movement**: walk onto an object to trigger it. This keeps the action space small and\nforces spatial reasoning — agents must navigate to the right objects.\n\n### Stepping the Environment"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "step-example",
   "metadata": {},
   "outputs": [],
   "source": "import numpy as np\n\n# Take 10 random steps\nfor _step in range(10):\n    actions = np.array([grid_env.single_action_space.sample() for _ in range(grid_env.num_agents)])\n    obs, rewards, terminals, truncations, infos = grid_env.step(actions)\n\nprint(f\"obs shape:          {obs.shape}\")\nprint(f\"rewards shape:      {rewards.shape}\")\nprint(f\"terminals shape:    {terminals.shape}\")\nprint(f\"truncations shape:  {truncations.shape}\")\nprint(f\"\\nRewards after 10 random steps: {rewards}\")\n\ngrid_env.close()"
  },
  {
   "cell_type": "markdown",
   "id": "next-steps",
   "metadata": {},
   "source": "## Next Steps\n\nNow that you know how the environment works, pick a role and train a specialist:\n\n- `TRAIN_MINER.ipynb` — Train a Miner (resource extraction and deposits)\n- `TRAIN_ALIGNER.ipynb` — Train an Aligner (heart management and junction capture)\n- `TRAIN_SCRAMBLER.ipynb` — Train a Scrambler (junction scrambling)\n- `TRAIN_SCOUT.ipynb` — Train a Scout (exploration and cell visitation)"
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".py",
    "format_name": "percent",
    "format_version": "1.3",
    "jupytext_version": "1.19.1"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}